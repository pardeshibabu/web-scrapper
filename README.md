# Web Scraper with Redis Caching and MongoDB Storage

## ğŸ“Œ Project Overview

This project is a web scraper built using Scrapy that extracts product data from an e-commerce website. It includes a MongoDB storage system and implements Redis caching to avoid unnecessary database writes when the product price remains unchanged.

## ğŸš€ Features

- Scrapes product details such as title, price, URL, and product ID.
- Stores product data in MongoDB.
- Uses Redis to cache the last known price and update the database only when the price changes.
- Implements multiprocessing to handle scraping tasks efficiently.
- Supports proxy configuration for anonymous scraping.

## ğŸ”§ Installation

### 1ï¸âƒ£ Clone the Repository

```sh
git clone https://github.com/your-username/web-scraper.git
cd web-scraper
```

### 2ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)

```sh
python3 -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
```

### 3ï¸âƒ£ Install Dependencies

```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Start Redis Server

Ensure Redis is running:

```sh
redis-server
```

### 5ï¸âƒ£ Set Up MongoDB

- Ensure you have MongoDB running locally or use a cloud service like MongoDB Atlas.
- Update the MongoDB connection details in `app/models/mongodb.py` if necessary.

### 6ï¸âƒ£ Run the Server Locally

Start the FastAPI server using Uvicorn:

```sh
uvicorn app.main:app --reload
```

## ğŸ“– REST API Documentation

Access the REST API documentation at:

[http://localhost:8000/docs](http://localhost:8000/docs)

## ğŸ›ªï¸ Project Structure

```
web-scraper/
â”‚â€”â€” app/
â”‚   â”œâ€” storage/
â”‚   â”‚   â”œâ€” base.py             # Abstract class for storage
â”‚   â”‚   â””â€” mongodb_storage.py  # MongoDB storage with Redis caching
â”‚   â”œâ€” models/
â”‚   â”‚   â””â€” mongodb.py          # MongoDB connection setup
â”‚â€”â€” scraper.py                  # Scrapy spider implementation
â”‚â€”â€” run_scraper.py              # Entry point for running scraper
â”‚â€”â€” requirements.txt            # Required dependencies
â”‚â€”â€” README.md                   # Project documentation
```

## ğŸ› ï¸ Technology Stack

- **Python** (Scrapy, multiprocessing)
- **MongoDB** (Data storage)
- **Redis** (Caching)
- **Docker** (Optional: for deployment)

## ğŸ³ Running with Docker (Optional)

```sh
docker-compose up --build
```

## âœ¨ Contributing

Feel free to fork and contribute by submitting a PR!

## ğŸ“œ License

This project is licensed under the MIT License.



